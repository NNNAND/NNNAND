# springcloud微服务

微服务技术栈

服务网关 注册中心拉取和注册服务信息 配置中心拉取配置信息 服务集群 消息队列来减少服务链路 分布式缓存 分布式搜索 数据库

对于这么庞大的服务，需要分布式日志服务来定位错误，还需要系统监控链路追踪

利用jenkins来部署服务，基于docker来打包形成镜像，利用kubernetes和rancher来进行实现自动化的部署。

## 五部分第一部分微服务治理

包括注册发现，远程调用，负载均衡，配置管理，系统保护，流量控制，网关路由，服务授权，熔断降级，分布式事务，ttc模型，at模型，seata。

这部分就是springclound的

### Eureka



## 第二部分异步通信技术

MQ消息模型，springAMQP，消息堆积问题，消息可靠性，仲裁队列，延迟队列，镜像集群，数据持久化

## 第三部分缓存

缓存穿透，雪崩；	springDataRedis，redis主从复制，OpenResty，缓存数据同步，nginx本地缓存，Redis持久化，多级缓存分层，Redis分片集群，lua脚本，Redis数据结构

## 第四部分持续集成DevOps技术

Dockerflie,DockerCompose,GrayLoy,Jenkins,SkyWalking,Docker使用，Kubernetes



## 第五部分分布式搜索

DSL语句，ES集群，RestAPI，集群脑裂，竞价排名，自动补全，聚合统计，拼音分词，地理坐标；

# 认识微服务

单体架构，将业务的所有功能集中在一个项目中开发，打成一个包部署

==优点==

- 架构简单
- 部署成本低

==缺点:==

- 耦合度高

***

分布式架构，根据业务功能对系统进行拆分，每个业务模块作为独立项目开发，称为一个服务。

==优点:==

- 降低服务耦合
- 有利于服务升级拓展

==缺点:难点==

- 整合难
- 服务拆分粒度
- 服务集群地址如何维护
- 服务如何实现远程调用
- 服务健康状态如何感知

***

==分布式中微服务就是一种经过良好架构设计的分布式架构方案，微服务架构特征：==

- 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责，避免重复业务开发
- 面向服务：微服务对外暴露业务接口，将来才可以远程调用
- 自治：团队独立、技术独立、数据独立（微服务每个数据库）、部署独立
- 隔离性强：服务调用做好隔离、容错、降级、避免出现级联问题

***

## 微服务技术对比

|                | Dubbo               | SpringCloud                | SpringCloudAlibaba              |
| -------------- | ------------------- | -------------------------- | ------------------------------- |
| 注册中心       | zookeeper、Redis    | Eureka、Consul             | Nacos(兼容两种服务调用)、Eureka |
| 服务远程调用   | Dubbo协议           | Feign(http协议)            | Dubbo、Feign                    |
| 配置中心       | 无                  | SpringCloudConfig          | SpringCloudConfig、Nacos        |
| 服务网关       | 无                  | SpringClound GateWay、Zuul | SpringCloudGateWay、Zuul        |
| 服务监控和保护 | dubbo-admin，功能弱 | Hystrix(保护)              | Sentinel                        |

***

==技术类型==

1. SpringCloud + Feign（Restful风格）
2. SpringCloudAlibaba +Feign（Restful风格）
3. SpringCloudAlibaba +Dubbo（Dubbo协议标准）
4. Dubbo老旧模式（Dubbo协议标准）

## 兼容性

| spring Cloud        | Boot Version                      |
| ------------------- | --------------------------------- |
| 2020.0.x aka llford | 2.4.x                             |
| Hoxton              | 2.2.x、2.3.x（Starting with SR5） |
| Green Wich          | 2.1.x                             |
| Finchley            | 2.0.x                             |
| Edgware             | 1.5.x                             |
| Dalston             | 1.5.x                             |

## 服务拆分和远程调用

### 远程调用

```java
// 1.在springboot启动项中注入这个类
@Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
// 2.利用RestTemplate发起http请求，查询用户
        String userUrl = "http://localhost:8081/user/"+order.getUserId();
        User user = restTemplate.getForObject(userUrl, User.class);
        // 3.封装user到order
        order.setUser(user);
```



### 服务拆分注意事项

1. 一个服务只做一个功能，不同微服务不要重复开发相同的业务。
2. 微服务的数据独立，不能访问其他微服务的数据库
3. 微服务将自己的业务暴露为接口，宫其他微服务调用

## Eureka注册中心

- 服务消费者该如何获取服务提供者的地址信息？

​		服务提供者启动时向eureka注册自己的信息

​		eureka保存这些信息

​		消费者根据服务名称向eureka拉取提供者信息

- 如果有多个服务提供者，消费者该如何选择呢？

​		服务消费者利用负载均衡算法，从服务列表中挑选一个

- 消费者如何得知服务提供者的健康状态呢？

​		心跳续约

​		eureka会更新记录服务列表信息，心跳不正常会被删除

​		消费者就可以拉取到最新的信息

# eureka-server 注册中心

两个微服务一个或者多个==consumer服务消费者==，和一个或者多个==Provider服务提供者==，都叫==eureka-client==

每个服务每隔30秒心跳续约，来检查服务是否健康。

==eureka作用==

1. 注册服务信息
2. 拉取服务
3. 负载均衡
4. 远程调用

### 如何注册

1. 引入依赖

```xml
<dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
        </dependency>
<dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
        </dependency>
```

2. 在application.yml中服务注册

```yaml
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
spring:
  application:
    name: eureka-server
```

### 服务发现

1. 修改Rrl为==userService==这个是eureka的注册名称

```java
String userUrl = "http://userService/user/"+order.getUserId();
```

2. ` @LoadBalanced`负载均衡

# 第二个组件Ribbon负载均衡

## 负载均衡原理

拦截请求后，找到指定服务，然后找到eureka，给了两个user Service，通过某种规则，选出一个，替换成真实的请求地址。

拦截的类是Load Balancer Interceptor它实现了一个接口为Client http Request Interceptor 客户端http请求拦截器 

在这个中有一个类名叫Ribbon Load  balancer Client会调一些类来完成上述过程。

## 负载均衡策略

I Rule接口来定义的

其中有Random Rule随机和Round Robin Rule轮询

1. 其中在application类中 注入一个bean(全局配置)访问任何一个微服务都是这个策略

```java
@Bean
public IRule randomRule(){
    return new RandomRule();
}
```

2. 配置文件方式：单独指定微服务在orderService服务中application.yml

```yaml
userservice:
	ribbon:
		NFLoadBalancerRuleClassName: 					com.netflix.loadbalancer.RandomRule #负载均衡规则
```

## 饥饿加载

Ribbon默认是采用懒加载，即第一次访问时才会去创建Load Balance Client，请求时间会很长。

而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载：

```yaml
ribbon:
  eager-load:
    enabled: true #开启饥饿加载
    clients: userservice #指定对userService这个服务饥饿加载
```

# 第三个组件Nacos

有分布式配置的功能

因为他们都是这个体系的所以不需要改代码，只需要依赖，和配置yaml文件即可

```java
<!-- springCloud nacos客户端 -->
            <dependency>
                <groupId>com.alibaba.cloud</groupId>
                <artifactId>spring-cloud-alibaba-dependencies</artifactId>
                <version>2.2.5.RELEASE</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
```

yaml文件

```java
<!-- nacos客户端依赖包 -->
<dependency>
    <groupId>com.alibaba.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
</dependency>
```



## nocos服务分级存储功能

1. 一级是服务
2. 集群
3. 实例

修改yml配置文件给个集群属性

`spring cloud nacos discovery cluster-name:`

## Nacos-Nacos Rule负载均衡

==集群特点==

- 优先访问本机集群
- 没有也可以跨集群访问，但是在日志会输出一个警告warn
- 在本机服务中采用随机负载均衡挑选实例

yml配置

`服务名 ribbon NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule`

## 根据权重负载均衡

在nacos中配置权重

1. 0-1之间
2. 权重越高越频繁
3. 0完全不会访问

## 环境隔离

Nacos中服务存储和数据存储的最外围都是一个名为name space的东西，用来做最外层隔离。

由外到内 name space	group	Service/Data

name space不同这个隔离域不可访问

yml配置	`cloud nacos discovery namespace: 命名ID`

## Nocas注册中心原理与Eureka对比

在拉取服务的时候，有个缓存列表在消费者服务中，每隔30秒刷新。

nocos频率快，在nocos中临时实例采用心跳检测机制，非临时不会，nacos会主动发请求询问你还活着吗，nacos不会把非临时实例从列表中剔除，标记为不健康。而在服务消费者Eureka采用30秒定时拉取，Nocos采用主动推送，变更消息。

nacos发现服务挂了就会立即推送给服务消费者说生产者挂了，服务列表缓存会发生更新。

在服务注册到nacos时，可以选择注册为临时或者非临时实例，通过以下来

==临时或者非临时实例==

yml	`spring cloud nacos discovery ephemeral: false`

Nacos集群默认强调服务的可用性AP方式，当集群中存在非临时实例时，采用CP模式。CP强调的是服务的可靠性和一致性；Eureka采用AP方式。不支持切换

## Nacos配置管理

### 统一配置管理

- 配置更改热更新

DataID：`userService-profile`dev开发环境 test prod

==配置获取步骤==(服务启动代码流程)

1. 项目启动

2. 读取Nacos配置文件(读取bootstrap.yml)

3. 读取本地配置文件

4. 创建spring容器

5. 加载bean

   ***

将配置交给Nacos管理的步骤

1. 在Nacos中添加配置文件
2. 在微服务中引入nacos的config依赖

```xml
<!--            nacos配置管理依赖-->
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
        </dependency>
```

3. 在微服务中加入引导文件`bootstrap.yml`，配置nacos地址，当前环境，服务名称，文件后缀名，这些决定了程序启动时去nacos读取哪个文件

### 配置自动更新

1. 方式一：在@Value注入的变量所在的类上面添加注解@Refresh Scope
2. 方式二：使用@Configuration properties注解

```java
@Data
@Component
@ConfigurationProperties(prefix = "pattern")
public class PatternProperties {
    private String dateformat;
}

```

### 微服务的配置共享

微服务启动时会从nacos读取多个配置文件

多种配置的优先级：

- 服务名-profile. yaml  > 服务名称 .yaml > 本机配置
- 远端的当前环境配置>远端配置>本地配置

### Nacos集群搭建



# Feign远程调用

## feign最佳实践

1. 方式一（继承）：给消费者的Feign Client和提供者Controller定义统一的父接口作为标准

==UserAPI==

2. 方式二（抽取）：将feignClient抽取为独立模块，并且把接口有关的POJO、默认的feign配置都放到这个模块中，提供给所有消费者使用



# Gate Way网关

- 身份认证和权限效验
- 服务路由，负载均衡
- 请求限流

spring cloud中有两个组件

1. gateway 新 	响应式编程
2. Zuul       阻塞式编程

搭建网关服务的步骤

1. 创建module 引入Spring Cloud Gateway的依赖和nacos的服务发现依赖

```java
  <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-gateway</artifactId>
        </dependency>
        <dependency>
            <groupId>com.alibaba.cloud</groupId>
            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
        </dependency>
```

2. 配置yaml文件

```java
server:
  port: 10010
spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: localhost:8848
      discovery:
        namespace: e7753cd0-93a1-432a-acf9-81c1b04290cb
    gateway:
      routes:
        - id: userService
#          uri: http://127.0.0.1:8848
          uri: lb://userService #lb是负载均衡，后面跟服务名称
          predicates: #路由断言
            - Path=/user/**  
        - id: orderService
          uri: lb://orderService
          predicates:
            - Path=/order/**
```

## 路由断言工厂 Route Predicate factory

- 我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件
- 例如Path=/user/**是按照路径匹配，这个规则是由org (spring framework) cloud gateway handler predicate (Path Route Predicate Factory)类来处理的
- 像这样的断言工厂在Spring Cloud Gateway还有几十个

## 路由过滤器配置

```yaml
spring:
  cloud:
    gateway:
	  routes:
	    - id:
	      filters:
	  default-filters:
	    - 
```

## 网关全局过滤器

过滤器的顺序order值越小，优先级越高

default-filters >filters>globalfilter

# Docker容器

大型不同组件兼容性问题

- 将依赖函数库，配置一起打包，形成可移植对象。
- 使用沙箱机制，互相隔离

如何解决开发，测试，生产环境有有差异的问题

- 将系统调用函数一起打包，直接调用系统内核，可以在任何linux操作系统。

## docker与虚拟机

hypervisor这个模拟计算机硬件，虚拟机狗都不用。

docker是进程，调用链的关系。

## 镜像和容器

docker将应用的程序及其所需的依赖，函数库，环境，配置等文件打包一起，称为镜像。

镜像中的应用程序运行后形成的进程就是容器，只是docker会给容器做隔离，对外不可见。进程觉得自己独占了操作系统。

在写文件的时候，自己在容器中data个文件夹，将镜像的拷贝过去，不可能往镜像里面去写。只读的镜像。

docker hub：docker hub是一个docker镜像托管平台。docker Registry

docker是一个cs架构的程序。

一个镜像可以运行多个容器

```shell
docker pull nginx:版本号
docker images
# repository nginx;tag latest;image id;created;size
docker save -o nginx.tar nginx:latest
docker rmi nginx:latest
docker images
docker load --help
docker load -i nginx.tar
```

```shell
docker pause 暂停
docker unpause 运行
docker stop
docker start
docker ps 查看所有运行的容器及状态
docker logs 
docker exec 进入容器执行命令
docker rm
```

```shell
docker run --name some-nginx -p  80:80 -d nginx
#80是宿主机,:左边容器的端口80 nginx默认
# -d: 后台运行容器
#nginx:镜像名称
docker ps
docker logs some-nginx
持续的监控日志
docker logs -f some-nginx

```

```shell
docker exec -it mn bash
-it 允许我们与容器交互
mn 容器名字
bash 进入是一个linux终端交互命令
变为root@唯一id:/# 进入了nginx的文件
hosting some simple static content
静态文件/usr/share/neinx/html
cat index.html
vi index.html 没有vi,文件系统是阉割版的
sed -i 's#Welcome to nginx#传智教育欢迎您#g' index.html
sed -i 's#<head>#<head><meta charset="utf-8">#g' index.html
退出容器
exit
docker ps
docker stop mn
docker ps 默认查看运行的容器
docker ps -a
docker start mn
docker ps
删除容器
docker rm mn 
docker rm --help
docker rm -f
docker ps -a
```

```shell
docker run --name mr -p 6379:6379 -d redis redis-server --appendonly yes
--appendonly持久化
docker ps
docker exec -it mr bash
redis-cli
>key *
>set num 666
>get num
>exit
exit
docker exec -it mr redis-cli
```

***

容器与数据耦合的问题
修改nginx的html	==不方便==
==数据不可复用==,对新创建的容器不可用
==升级维护困难== 数据在容器内,如果要升级容器必然删除旧容器,所有数据也就删除了

数据卷(volume)是一个虚拟目录,指向宿主机文件系统中的某个目录

/var/lib/docker/volumes/html

```shell
数据卷命令
docker volume [command]
create 创建volume
inspect 显示一个或者多个volume还有一些详细信息
ls 
prune 删除未使用的
rm
docker volume --help
docker volume create html
docker volume ls mountpoint
docker prune 
docker volume rm html
```

```shell
docker run -v html:/usr/share/nginx/html 数据卷挂载
cd /var/lib/docker/volumes/thml/_data
ls
数据卷不存在会自动创建


```

```shell
宿主机目录可以直接挂载到容器
容器运行
docker run \
	--name mysql \
	-e MYSQL_ROOT_PASSWORD=123 \
	-p 3306:3306 \
	-v /tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf \
	-v /tmp/mysql/data:/var/lib/mysql \
	-d \ 
	mysql:5.7.25
```

## 镜像结构

镜像是将应用程序及其需要的==系统函数库,环境,配置,依赖打包而成==。

依赖顺序，基础镜像（baseimage）应用依赖的系统函数库，环境，配置，文件等

层，在baseimage基础上添加安装包，配置，依赖，每次操作的是新的一层

入口，镜像运行入口脚本，一般是程序的启动脚本

## 自定义镜像

| 指令       | 说明                                         | 实例                        |
| ---------- | -------------------------------------------- | --------------------------- |
| from       | 指定基础镜像                                 | from centos:6               |
| env        | 设置环境变量，可在后面的指令使用             | env key value               |
| copy       | 拷贝本地文件到镜像的指定目录                 | copy ./mysql-5.7.rpm /tmp   |
| run        | 执行linux的shell命令，一般是安装过程的命令   | run yum install gcc         |
| expose     | 指定容器运行时监听的端口，是给镜像使用者看的 | expose 8080                 |
| entrypoint | 镜像应用的启动命令，容器运行时调用           | entrypoint java -jar xx.jar |

# MQ

## 同步通讯的优缺点

微服务基于feign的调用就是同步，时效性高

缺点

耦合度高，每次的新需求就要修改代码

性能下降，调用链过于长

资源浪费，每个服务在等待响应的过程中，不能释放请求占用的资源

级联失败，如果服务提供者出现问题，整个微服务群都会故障。

## 异步通讯

常见实现事件驱动模式

服务提供者只需要订阅事件，这个订阅事件就是接受通知，这种情况就是服务解耦，服务消费者之需要发布事件

优势

1. 服务解耦
2. 性能提升，吞吐量提高
3. 没有强依赖，不担心级联失败问题，也不存在资源浪费
4. 流量消峰
5. 将这种高并发设置大坝，能服务多少就服务多少

缺点

1. 依赖于borker的可靠性，安全性，吞吐能力
2. 架构复杂了，业务追踪没有明显的流程线，不好追踪管理

mq，中文是消息队列，字面来看就是存放消息队列。也就是事件驱动结构中的broker

|            | RabbitMQ             | ActiveMQ                        | RocketMQ | Kafka      |
| ---------- | -------------------- | ------------------------------- | -------- | ---------- |
| 公司/社区  | Rabbit               | apache                          | 阿里     | apache     |
| 开发语言   | Erlang               | java                            | java     | Scala&java |
| 协议支持   | AMQP,XMPP,SMTP,STOMP | OpenWire，STOMP，REST,XMPP,AMQP | 自定义   | 自定义     |
| 可用性     | 高                   | 一般                            | 高       | 高         |
| 单机吞吐量 | 一般                 | 差                              | 高       | 非常高     |
| 消息延迟   | 微妙级               | 毫秒级                          | 毫秒级   | 毫秒以内   |
| 消息可靠性 | 高                   | 一般                            | 高       | 一般       |

## RabbitMQ

Erlang面向并发来设计的RabbitMQ高可用

```shell
docker
[root@nosql01 tmp]# docker run \
> -e RABBITMQ_DEFAULT_USER=itcast \
> -e RABBITMQ_DEFAULT_PASS=123321 \
> --name mq \
> --hostname mq1 \
> -p 15672:15672 \
> -p 5672:5672 \
> -d \
> rabbitmq:3-management
```

整体流程，消息发送者发送消息给交换机，交换机选择发送到哪个队列，然后对列中的消息提供给消息接受者，通过VirtualHost来隔离每个用户不同的操作

- channel 操作mq的工具
- exchange：路由消息到队列中
- queue：缓存消息
- virtual host：虚拟主机，是对queue，exchange等资源的逻辑分组

## MQ常见框架

1. 基本消息队列（basic queue）

publisher：消息发送者

queue：消息列

consumer：订阅队列

2. 工作消息队列（work queue）

发布订阅，又根据交换机类型不同分为三种

- fanout exchange：广播
- direct exchange：路由
- topic exchange：主题

```java
package cn.itcast.mq.helloworld;

import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;
import org.junit.Test;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class PublisherTest {
    @Test
    public void testSendMessage() throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost("192.168.121.134");
        factory.setPort(5672);
        factory.setVirtualHost("/");
        factory.setUsername("itcast");
        factory.setPassword("123321");
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = "simple.queue";
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.发送消息
        String message = "hello, rabbitmq!";
        channel.basicPublish("", queueName, null, message.getBytes());
        System.out.println("发送消息成功：【" + message + "】");

        // 5.关闭通道和连接
        channel.close();
        connection.close();

    }
}
*********************************************
*********************************************
package cn.itcast.mq.helloworld;

import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;
import org.junit.Test;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class PublisherTest {
    @Test
    public void testSendMessage() throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost("192.168.121.134");
        factory.setPort(5672);
        factory.setVirtualHost("/");
        factory.setUsername("itcast");
        factory.setPassword("123321");
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = "simple.queue";
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.发送消息
        String message = "hello, rabbitmq!";
        channel.basicPublish("", queueName, null, message.getBytes());
        System.out.println("发送消息成功：【" + message + "】");

        // 5.关闭通道和连接
        channel.close();
        connection.close();

    }
}

```



## springAMQP

advanced message queuing protocol 高级消息队列协议

应用程序或者之间传递业务消息的开发标准。该协议与语言和平台无关，更符合微服务中独立性的要求。

spring AMQP是基于amqp协议定义的一套api规范，提供了模版来发送和接收消息。包含两部分，其中spring0amqp是基础抽象，spring-rabbit是底层的默认实现。

简化了基本的连接

```java
package cn.itcast.mq.helloworld;

import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.amqp.rabbit.core.RabbitAdmin;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

@RunWith(SpringRunner.class)
@SpringBootTest
public class MQTest {
    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Test
    public void name() {
        String queueName = "simple queue";
        String message = "hell spring amqp";
        rabbitTemplate.convertAndSend(queueName,message);
    }
}
**************************************
@Component
public class MQAmqp {
    @RabbitListener(queues = "simple.queue")
    public void listenSimpleQueueMessage(String msg) throws InterruptedException{
        System.out.println("spring 消息接受者收到消息: [" + msg + "]");
    }
}
```

==work queue== 实现一个对列绑定多个消费者

消息预取机制，

```yaml
logging:
  pattern:
    dateformat: MM-dd HH:mm:ss:SSS
spring:
  rabbitmq:
    host: 192.168.121.134
    port: 5672
    username: itcast
    password: 123321
    virtual-host: /
    listener:
      simple:
        prefetch: 1 #每次只能取一个消息，处理完再取下一条

```

### 发布消息，订阅消息

同一个消息发送给多个消费者，实现的方式是加入了exchange（交换机）。

广播，路由，话题

广播就是将消息路由到每一个绑定的队列

```java
@Configuration
public class ExAndQueue {
    @Bean
    public FanoutExchange fanoutExchange(){
        return new FanoutExchange("itcast.fanout");
    }
    @Bean
    public Queue fanoutQueue1(){
        return new Queue("fanout.queue1");
    }
    @Bean
    public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){
        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);
    }
    @Bean
    public Queue fanoutQueue2(){
        return new Queue("fanout.queue2");
    }
    @Bean
    public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange){
        return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange);
    }
}
************************************************
   @Test
    public void testSendFanoutExchange(){
        String exchangeName = "itcast.fanout";
        String massage = "nimenhao";
        rabbitTemplate.convertAndSend(exchangeName,"",massage);
    }
```

==routes模式 DirectExchange==

每一个Queue都与Exchange设置一个Binding Key

发布这发送消息时，指定小的Routing Key

exchange将消息路由到BindingKey与消息RoutingKey一致的队列

利用@Rabbit Listener声明Exchange，Queue，Routing Key。这都是绑定的

```java
@RabbitListener(bindings = @QueueBinding(
            value = @Queue(name = "direct.queue1"),
            exchange = @Exchange(name = "itcast.direct", type = ExchangeTypes.DIRECT),
            key = {"red","blue"}
    ))
    public void listenDirectQueue1(String msg){
        System.out.println("消费者接收到的是direct.queue1的消息：[" + msg + "]");
    }

```

Topic Exchange通配符简化了Binding key #：代表多个单词，*：代表一个单词

```java
序列化方式
 @Bean
    public MessageConverter messageConverter(){
        return new Jackson2JsonMessageConverter();
    }
依赖;
 <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
        </dependency>
```

# 分布式搜索

elasticsearch基础

## 了解ES

开源搜索引擎，从海量数据中快速找到需要的内容

elasticsearch结合了kibana，logstash，beats，也就是elastic stack（ELK）。被广泛应用在日志数据分析，事实监控等领域。

kibana数据可视化，elasticssearch是存储，计算，搜索数据；logstash，beats这些是数据抓取。

==技术实现底层==是：lucene是java语言的搜索引擎类库，是apache公司的顶级项目，由DougCutting于1999年研发。

lucene的优势：

- 易扩展
- 高性能（基于倒排索引）

lucene的缺点

- 只限于java开发
- 学习曲线陡峭
- 不支持水平扩展

相比于lucene，elasticsearch具备下列优势：

- 支持分布式，可水平扩展
- 提供restful接口，可被任何语言调用

## 倒排索引

传统数据库采用如（MySQL）采用正向索引，例如给下表用模糊匹配，这种得一行一行扫描，性能差。

- 文档：每条数据就是一个文档
- 词条：文档按照语义分成的词语

词条字段的唯一性，B+树；利用文档id找，B+树，两次索引这种速度也是非常快的。

## es的概念

==文档==可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化成json格式，存储在es中

==索引==：相同类型的文档的集合

| MySQL  | Elasticsearch | 说明                                                         |
| ------ | ------------- | ------------------------------------------------------------ |
| table  | index         | 索引，就是文档的集合，类似于数据库的表                       |
| row    | Document      | 文档，就是一条一条的数据，类似于数据库中的行，文档就是json格式 |
| column | Field         | 字段，就是json文档中的字段，类似于数据库中的列               |
| Schema | Mapping       | 映射是索引中文档的约束，类似于字段类型的约束，类似于数据库的表结构 |
| SQL    | DSL           | DSL是elasticsearch提供的json风格的请求语句，用来操作elasticsearch，实现CRUD |

MySQL：擅长事务类型操作，可以确保数据的安全性和一致性

elastic search：擅长海量数据的分析，搜索，计算。

```hsell
find . -type f | du -ahx . | sort -rh |head -n 10
sudo du -h --max-depth=1 /只显示一级	目录

```

```shell
docker volume inspect es-plugins
```

ik_max_word ,细度高

ik_smart,粒度不是那么细,最小切分

## 索引库操作

mapping映射属性 约束

type：字段数据类型常见的简单类型

- text可分词的文本
- keyword精确值，例如品牌，国家 ，ip地址

数值

类型 ：long ，integer，short，byte，bouble，float

布尔，日期，对象嵌套

****

index是否创建索引，默认为true

analyzer：是否使用分词器

properties：该字段的子字段

### 创建索引库

```json
PUT /itheima
{
  "mappings":{
    "properties":{
      "info": {
        "type":"text",
        "analyzer":"ik_smart"
      },
      "email":{
        "type":"keyword",
        "index":false
      },
      "name":{
        "type": "object", 
        "properties":{
          "firstName":{
            "type":"keyword"
          },
          "lastName":{
            "type":"keyword"
          }
        }
      }
    }
  }
}
```

查询，删除索引库

GET /索引库名

DELETE  /索引库名

修改索引库

```json
PUT /索引库名/_mapping
{
  "properties":{
    "新字段名":{
      "type":"integer"
    }
  }
}
```

### 文档操作

```json
POST /索引库名/_doc/文档id
{
  "info": "值1"，
  "字段名": "值2",
  "name": {
  	"firstName":"云",
  	"lastName": "赵"
	}
}
GET /索引库名/_doc/文档id
DELETE /索引库名/_doc/文档id
修改文档
1.全量修改,如果在索引库中存在就是修改,如果不在其实就是新增
PUT /索引库名/_doc/文档id
{
  "info": "值1"，
  "字段名": "值2",
  "name": {
  	"firstName":"云",
  	"lastName": "赵"
	}
}
2.局部修改,自更新一个字段
POST /索引库名/_update/文档id
{
  "doc": {
    "email": "修改值"
  }
}
```

### RestClient

各种语言的客户端,本质是封装了SDL语句的请求。

```json
PUT /hotel
{
  "mappings":{
    "properties":{
      "id":{
        "type": "keyword",
      },
      "name":{
        "type": "text",
        "analyzer": "ik_max_word",
        "copy_to": "all"
      },
      "address":{
        "type": "keyword",
      	"index": false
      },
      "price":{
        "type": "integer"
      },
      "score":{
        "type": "integer"
      },
      "brand":{
        "type": "keyword",
        "copy_to": "all"
      },
      "city":{
        "type": "keyword"
      },
      "starName":{
        "type": "keyword"
      },
      "business":{
        "type": "keyword",
        "copy_to": "all"
      },
      "location":{
        "type": "geo_point"
      },
      "pic":{
        "type": "keyword",
        "index": false
      },
      "all":{
        "type": "text",
        "analyzer": "ik_max_word"
      }
    }
  }
}
```

geo_point：地图上的一个点

geo_shape：地图上的位置

### javaAPI

```java
public class HotelTest {

    private RestHighLevelClient restHighLevelClient;

    @BeforeEach
    void setUp() {
        this.restHighLevelClient = new RestHighLevelClient(RestClient.builder(
                HttpHost.create("http://192.168.121.134:9200")
        ));
    }

    @Test
    void name() {
        System.out.println(restHighLevelClient);
    }

    @Test
    void testCreatehotelIndex() throws IOException {
        // 1.创建request对象
        CreateIndexRequest request = new CreateIndexRequest("hotel");
        // 2.请求参数，内容是创建SDL语句
        request.source(MAPPING_TEMPLATE, XContentType.JSON);
        // 3.发起请求
        restHighLevelClient.indices().create(request, RequestOptions.DEFAULT);
    }

    @Test
    void existIndex() throws IOException {
        GetIndexRequest request = new GetIndexRequest("hotel");
        boolean exists = restHighLevelClient.indices().exists(request, RequestOptions.DEFAULT);
        System.out.println(exists);
    }

    @Test
    void DeleteIndex() throws IOException {
        DeleteIndexRequest request = new DeleteIndexRequest("hotel");
        restHighLevelClient.indices().delete(request,RequestOptions.DEFAULT);
    }

    @AfterEach
    void tearDown() throws IOException {
        this.restHighLevelClient.close();
    }
}
```

```java
//文档的增删改查
public class DocumentationCRUD {
    @Autowired
    private IHotelService hotelService;
    private RestHighLevelClient client;
    @BeforeEach
    void setUp() {
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create("http://192.168.121.134:9200")
        ));
    }

    @Test
    void testIndexDocument() throws IOException {
        Hotel hotel = hotelService.getById(60522L);
        HotelDoc hotelDoc = new HotelDoc(hotel);
        IndexRequest indexRequest = new IndexRequest("hotel").id(hotel.getId().toString());
        //JSON.toJSONString
        indexRequest.source(JSON.toJSONString(hotelDoc), XContentType.JSON);
        client.index(indexRequest, RequestOptions.DEFAULT);
    }

    @Test
    void getDocumentById() throws IOException {
        GetRequest getRequest = new GetRequest("hotel").id("60522");
        GetResponse documentFields = client.get(getRequest, RequestOptions.DEFAULT);
        String json = documentFields.getSourceAsString();
        System.out.println(json);
        //反序列化为对象
        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
    }

    @Test
    void batAddDoc() throws IOException {
        List<Hotel> hotels = hotelService.list();
        BulkRequest request = new BulkRequest();
        for(Hotel hotel : hotels){
            HotelDoc hotelDoc = new HotelDoc(hotel);
            request.add(new IndexRequest("hotel")
                .id(hotelDoc.getId().toString())
                .source(JSON.toJSONString(hotelDoc),XContentType.JSON)
            );
        }
        client.bulk(request,RequestOptions.DEFAULT);
    }

    @Test
    void updateDoc() throws IOException {
        UpdateRequest request = new UpdateRequest("hotel", "60522");
        request.doc(
                "price",425,
                        "city","上海"
        );
        client.update(request,RequestOptions.DEFAULT);
        getDocumentById();
    }

    @Test
    void DeleteDoc() throws IOException {
        DeleteRequest deleteRequest = new DeleteRequest("hotel","60522");
        DeleteResponse delete = client.delete(deleteRequest, RequestOptions.DEFAULT);
        System.out.println(delete.toString());
    }

    @AfterEach
    void tearDown() throws IOException {
        client.close();
    }
}
```

Query DSL

- 查询所有：查询出所有数据，一般测试用。例如：match_all
- 全文检索查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：match_query     multi_match_query
- 精确查询：根据精确词条查找数据，一般是查找keyword，数值，日期，boolean等类型字段。例如：ids：id查询     range：范围    tarm：值
- 地理查询：根据经纬度查询。例如 gen_distance   gen_bounding_box
- 符合查询：符合查询可以将上述查询条件组合起来，合并查询条件。例如：bool：逻辑     function_score

```java
查询所有
GET /indexName/_search
{
  "query":{
    "查询类型":{
      "查询条件": "条件值"
    }
  }
}
全文检索;
GET /indexName/_search
{
  "query":{
    "mathch":{
      "FIFLD": "TEXT"
    }
  }
}
match查询例子，单字段查询性能好
GET /hotel/_search
{
  "query":{
    "match":{
      "all": "外滩"
    }
  }
}
multi_match查询，注意不要写错
GET /indexName/_search
{
  "query":{
    "multi_match":{
      "query": "外滩",
      "fields": ["brand","name","business"]
    }
  }
}
```

```java
# 精确查询，不会分词
term精确 
GET /indexName/_search
{
  "query":{
    "term":{
      "city":{
        "value": "杭州"
      }
    }
  }
}
range范围
GET /indexName/_search
{
  "query":{
    "range":{
      "FIELD":{
        "gte": 10,
        "lte": 20
      }
    }
  }
}

```

查询我附近的一些酒店，出租车，我附近的人

```java
地理查询
geo_bounding_box
GET /indexName/_search
{
  "query":{
    "geo_bounding_box":{
      "FIELD":{
        "lat":     ,
        "lon": 
      },
      "bottom_right":{
        "lat":30.9,
        "lon":121.7
      }
    }
  }
}
geo_distance
GET /indexName/_search
{
  "query":{
    "distance": {
      "distance": "15km",
    	"FIELD": "31.21, 121.5"
    }
  }
}
```

复合查询

```java
fuction score:算分函数查询，相关性打分
人工对搜索排名进行干预
TF词条频率= 词条出现的次数/文档中词条的总数
IDF逆文档频率 = log（文档总数/包含词条的文档总数）
score = TF * IDF
BM25算法
区别在于词频越大，一个越来越大，一个趋向水平，
function score查询
GET /hotel/_search
{
  "query":{
    "function_score":{
      "query": {
        "match":{
          "all": "外滩"
        }
      },
      "functions":[
        {
          "filter":{
            "term":{
              "brand": "如家"
            }
          },
          "weight": 10
        }
      ],
      "boost_mode": "sum"
    }
  }
} 
```

复合查询 boolean Query

布尔查询是一个或者多个查询子句的组合。子查询的组合方式有：

- must：必须匹配每个子查询，类似与
- should：选择性匹配子查询，类似或者
- must_not：不许不匹配，不参与算分，类似非
- filter：必须匹配，不参与算分

```java
GET /hotel/_search
{
  "query":{
    "bool":{
      "must":[
        {
          "term": {"city":"上海"}
        }
      ],
      "should": [
        {"term": {"brand": "皇冠假日"}},
        {"term":{"brand": "华美达"}}
      ],
      "must_not":[
        {"range":{"price":{"lte": 500 }  }},
      ],
      "filter":[
        {"range": {"score": {"gte": 45}    }}
      ]
    }
  }
}

GET /hotel/_search
{
  "query":{
    "bool":{
      "must":[
        {"match":{"name": "如家"} }
      ],
      "must_not":[
        {
          "range":{
                    "price": {"gt": "400"}
                  }
        }
      ],
      "filter":[
        {
          "geo_distance":{
            "distance": "10km",
            "location": {
              "lat": 31.21, "lon": 121.5
            }
          }
        }
      ]
    }
  }
}
```

### 排序/分页

可以排序字段类型有：keyword，数值，地理坐标，日期。

```json
GET /indexName/_search
{
  "query":{
    "match_all":{}
  },
  "sort": [
    {
      "score": "desc"
    },
    {
      "price": "asc"
    }
  ]
}

GET /hotel/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "_geo_distance": {
        "location": {
          "lat": 31.034661,
          "lon": 121.612282
        },
        "order": "asc",
        "unit": "km"
      }
    }
  ]
}

分页查询
GET /hotel/_search
{
  "query": {
    "match_all": {}
  },
  "from": 0,
  "size": 201,
  "sort": [
    {
      "price": "asc" 
    }
  ]
}


```

### 深度分页问题

因为分布式系统的是集群的，我想查全索引前1000条，我就得选出每个服务器的1000条，聚合排序，找出前1000条

上限不能超过10000 "from": 9991, "size":10

解决方案，

search after ：分页时需要分页，原理从上一次的排序值，查询下一页数据。场景：例如手机向下滚动翻页

scroll：会有额外内存消耗，并且搜索结果是非实时的，场景：海量数据的获取和迁移。基本不推荐使用

### 高亮处理

em标签

服务端用标签标记出来

在页面中给标签添加css样式

```java
GET /hotel/_search
{
  "query":{
    "match":{
      "all": "如家"
    }
  },
  "highlight":{
    "fields":{
      "name":{
        "require_field_match": "false"
      }
    }
  }
}
```

RestClient查询javaAPI实现

### es数据聚合

可以实现对文档数据的统计，分析，运算。聚合常见的有三类

- 桶聚合：用来对文档做分组
  - term Aggregation：按照文档字段值分组
  - Date Histogram：按照日期阶梯分组，例如一周为一组，或者一个月为一组
- 度量聚合：用于计算一些值，比如：最大值，最少值，平均值
- 管道聚合：其他聚合的结果为基础做聚合

### 自动补全

补全你输入的数据

### 数据同步

mysql和elastic search

方案一：同步调用 

1. 写入数据库
2. 调更新索引库接口
3. 更新elastic search

方案二：异步通知

1. 写入数据库
2. 发布消息
3. 监听消息
4. 更新elastic search

方案三：监听binlog（耦合度最低，但是需要canal）

1. 写入数据库
2. 监听mysql的binlog
3. 通知酒店的数据变更情况
4. 更新elastic search

### es集群

### 分布式事务

- 跨服务，跨数据源的业务
- 思考如何解决
- 了解seata框架，学习seata原理

seata架构

transaction coordinator事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。

transaction manager事务管理器：定义全局事务的范围，开始全局事务，提交或者回滚事务。

resource manager 资源管理器：管理分支事务处理的资源，于tc交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。
